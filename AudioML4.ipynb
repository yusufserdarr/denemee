{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dosyaları 1.5 snlik dosyalara ayırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "# MP3 dosyalarının bulunduğu dizin\n",
    "mp3_dir = \"Dosyalar/Fatih-Müyesser-mp3\"\n",
    "# WAV dosyalarının kaydedileceği dizin\n",
    "wav_dir = \"Dosyalar/Fatih-Müyesser-wav\"\n",
    "\n",
    "# MP3 dosyalarının listesi\n",
    "mp3_files = os.listdir(mp3_dir)\n",
    "\n",
    "# Her MP3 dosyasını işleyin\n",
    "for mp3_file in mp3_files:\n",
    "    # MP3 dosyasını yükle\n",
    "    audio = AudioSegment.from_mp3(os.path.join(mp3_dir, mp3_file))\n",
    "    # 1.5 saniyelik parçalara böl\n",
    "    chunks = audio[::1000]\n",
    "    \n",
    "    # Parçaları kaydet\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk.export(os.path.join(wav_dir, f\"{mp3_file[:-4]}_{i}.wav\"), format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCC özelliklerini çıkarmak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Ön İşleme ve Özellik Çıkarımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC özellikleri başarıyla oluşturuldu.\n",
      "(128, 151)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Ses dosyalarının bulunduğu dizin\n",
    "ses_dizin = 'Dosyalar/Fatih-Müyesser-Sümeyye-Talha-wav'\n",
    "\n",
    "# MFCC özelliklerinin kaydedileceği dizin\n",
    "mfcc_dizin = 'Dosyalar/Fatih-Müyesser-Sümeyye-Talha-mfcc'\n",
    "\n",
    "# MFCC parametreleri\n",
    "n_mfcc = 128\n",
    "\n",
    "# Framelere ayırma parametreleri\n",
    "frame_length = 25  # milisaniye cinsinden\n",
    "frame_stride = 10   # milisaniye cinsinden\n",
    "\n",
    "# Dosyaları işleme\n",
    "for dosya_adı in os.listdir(ses_dizin):\n",
    "    if dosya_adı.endswith('.wav'):\n",
    "        dosya_yolu = os.path.join(ses_dizin, dosya_adı)\n",
    "        ses, sr = librosa.load(dosya_yolu, sr=None)\n",
    "        mfcc = librosa.feature.mfcc(y=ses, sr=sr, n_mfcc=n_mfcc, hop_length=int(frame_stride * sr / 1000),\n",
    "                                     n_fft=int(frame_length * sr / 1000))\n",
    "        mfcc_dosya_adı = dosya_adı.split('.')[0] + '.npy'\n",
    "        mfcc_dosya_yolu = os.path.join(mfcc_dizin, mfcc_dosya_adı)\n",
    "        np.save(mfcc_dosya_yolu, mfcc)\n",
    "\n",
    "print(\"MFCC özellikleri başarıyla oluşturuldu.\")\n",
    "print(mfcc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeli Eğitmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doğruluğu: 0.9875\n",
      "(316, 128)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# MFCC özelliklerinin bulunduğu dizin\n",
    "mfcc_dizin = 'Dosyalar/Fatih-Müyesser-Sümeyye-mfcc/'\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# MFCC dosyalarını yükleme\n",
    "for dosya_adı in os.listdir(mfcc_dizin):\n",
    "    if dosya_adı.endswith('.npy'):\n",
    "        dosya_yolu = os.path.join(mfcc_dizin, dosya_adı)\n",
    "        mfcc = np.load(dosya_yolu)\n",
    "        X.append(np.mean(mfcc, axis=1))  # Her dosya için ortalama MFCC vektörü\n",
    "        y.append(dosya_adı.split(' ')[0])  # Dosya adından etiket çıkarma\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Etiketleri sayısal değerlere dönüştürme\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Veri kümesini eğitim ve test kümelerine ayırma\n",
    "X_egitim, X_test, y_egitim, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MLP modeli oluşturma ve eğitme\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "model.fit(X_egitim, y_egitim)\n",
    "\n",
    "# Modelin doğruluğunu değerlendirme\n",
    "dogruluk = model.score(X_test, y_test)\n",
    "print(f\"Model doğruluğu: {dogruluk}\")\n",
    "\n",
    "print(X_egitim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-fatih-müyesser-sümeyye.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeli diske kaydetme\n",
    "model_kayit_yolu = 'model-fatih-müyesser-sümeyye.pkl'\n",
    "joblib.dump(model, model_kayit_yolu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        39\n",
      "           1       0.95      1.00      0.98        20\n",
      "           2       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.98      0.99      0.99        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n",
      "Karışıklık Matrisi:\n",
      "[[38  1  0]\n",
      " [ 0 20  0]\n",
      " [ 0  0 21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Test veri seti üzerinde tahmin yapma\n",
    "tahminler = model.predict(X_test)\n",
    "\n",
    "# Sınıflandırma raporu ve karışıklık matrisini yazdırma\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, tahminler))\n",
    "\n",
    "print(\"Karışıklık Matrisi:\")\n",
    "print(confusion_matrix(y_test, tahminler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uygulama Geliştirme - Dosya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin edilen kişi:  [0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Eğitilmiş modeli yükleme\n",
    "model_kayit_yolu = 'model-fatih-müyesser-talha-sümeyye.pkl'\n",
    "model = joblib.load(model_kayit_yolu)\n",
    "\n",
    "# Test edilecek ses dosyasının MFCC özelliklerini yükleme\n",
    "test_ses_dosyasi = 'Dosyalar/Fatih-Müyesser-Sümeyye-Talha-mfcc/Müyesser (1).npy'\n",
    "mfcc = np.load(test_ses_dosyasi)\n",
    "\n",
    "# Model üzerinden tahmin yapma\n",
    "tahmin = model.predict(np.mean(mfcc, axis=1).reshape(1, -1))\n",
    "\n",
    "# Tahmini sonuç\n",
    "print(\"Tahmin edilen kişi: \", tahmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uygulama Geliştirme - Mikrofon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konuşun...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 431 features, but MLPClassifier is expecting 128 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m mfcc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(mfcc\u001b[38;5;241m.\u001b[39mT, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ortalama MFCC vektörü\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Model üzerinden tahmin yapma\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m tahmin_indeksi \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfcc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     35\u001b[0m tahmin_isim \u001b[38;5;241m=\u001b[39m sinif_isimleri[tahmin_indeksi]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Tahmini sonuç\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1160\u001b[0m, in \u001b[0;36mMLPClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the multi-layer perceptron classifier.\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \n\u001b[0;32m   1149\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;124;03m    The predicted classes.\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1164\u001b[0m, in \u001b[0;36mMLPClassifier._predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1164\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1167\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:207\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mThis is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m    The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[1;32m--> 207\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Initialize first layer\u001b[39;00m\n\u001b[0;32m    210\u001b[0m activation \u001b[38;5;241m=\u001b[39m X\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 431 features, but MLPClassifier is expecting 128 features as input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import joblib\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "# Eğitilmiş modeli yükleme\n",
    "model_kayit_yolu = 'model-fatih-müyesser-sümeyye.pkl'\n",
    "model = joblib.load(model_kayit_yolu)\n",
    "\n",
    "sinif_isimleri = ['Fatih','Sümeyye','Müyesser']\n",
    "\n",
    "# Mikrofondan ses almak için gerekli parametreler\n",
    "saniye_basina_ornek = 44100  # Örnekleme hızı (örneğin, 44100 Hz)\n",
    "saniye = 5  # 5 saniyelik ses al\n",
    "kanal_sayisi = 1  # Tek kanallı ses\n",
    "\n",
    "while True:\n",
    "    print(\"Konuşun...\")\n",
    "    ses = sd.rec(int(saniye_basina_ornek * saniye), samplerate=saniye_basina_ornek, channels=kanal_sayisi, dtype='float32')\n",
    "    sd.wait()  # Ses alımının tamamlanmasını bekleyin\n",
    "    \n",
    "    # Ses dosyasını WAV olarak kaydetme\n",
    "    kayit_yolu = \"kayit.wav\"\n",
    "    sf.write(kayit_yolu, np.squeeze(ses), saniye_basina_ornek)\n",
    "    \n",
    "    # WAV dosyasını yükleme ve MFCC özelliklerini çıkarma\n",
    "    y, sr = librosa.load(kayit_yolu, sr=saniye_basina_ornek)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=128)\n",
    "    mfcc = np.mean(mfcc.T, axis=0)  # Ortalama MFCC vektörü\n",
    "    \n",
    "    # Model üzerinden tahmin yapma\n",
    "    tahmin_indeksi = model.predict(mfcc.reshape(1, -1))[0]\n",
    "    tahmin_isim = sinif_isimleri[tahmin_indeksi]\n",
    "    \n",
    "    # Tahmini sonuç\n",
    "    print(\"Tahmin edilen kişi: \", tahmin_isim)\n",
    "    #os.remove(kayit_yolu)  # Kayıt dosyasını temizleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript:\n",
      "Could not request results; recognition connection failed: [Errno 11001] getaddrinfo failed\n",
      "Kelime Sayısı:\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_mp3_to_wav(mp3_file_path, wav_file_path):\n",
    "    audio = AudioSegment.from_mp3(mp3_file_path)\n",
    "    audio.export(wav_file_path, format=\"wav\")\n",
    "\n",
    "def transcribe_audio(audio_file_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file_path) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        transcript = recognizer.recognize_google(audio, language=\"tr-TR\")\n",
    "        return transcript\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results; {e}\"\n",
    "\n",
    "kelimeler = []\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wav_file_path = \"kayit.wav\"  # Path to the converted WAV file\n",
    "\n",
    "    # Transcribe the WAV file-\n",
    "    transcript = transcribe_audio(wav_file_path)\n",
    "    \n",
    "    kelimeler.extend(transcript.split())\n",
    "    \n",
    "    print(\"Transcript:\")\n",
    "    print(transcript)\n",
    "    \n",
    "    print(\"Kelime Sayısı:\")\n",
    "    print(len(kelimeler))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
